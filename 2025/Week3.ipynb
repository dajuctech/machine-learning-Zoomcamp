{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "692c4e65-c08c-46b4-ad3b-7be5eaec8a26",
   "metadata": {},
   "source": [
    "### Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9eaff732-7ab2-4d1b-9061-abee8fa94a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d911ea7-e3f5-42cc-85b7-d2b04e7a7539",
   "metadata": {},
   "source": [
    "### Load and Explore Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d5da16c-b97e-4d6a-b445-7dd07aeb7418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (1462, 9)\n",
      "Columns: ['lead_source', 'industry', 'number_of_courses_viewed', 'annual_income', 'employment_status', 'location', 'interaction_count', 'lead_score', 'converted']\n",
      "\n",
      "First 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lead_source</th>\n",
       "      <th>industry</th>\n",
       "      <th>number_of_courses_viewed</th>\n",
       "      <th>annual_income</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>location</th>\n",
       "      <th>interaction_count</th>\n",
       "      <th>lead_score</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>paid_ads</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>79450.0</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>south_america</td>\n",
       "      <td>4</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>social_media</td>\n",
       "      <td>retail</td>\n",
       "      <td>1</td>\n",
       "      <td>46992.0</td>\n",
       "      <td>employed</td>\n",
       "      <td>south_america</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>events</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>5</td>\n",
       "      <td>78796.0</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>australia</td>\n",
       "      <td>3</td>\n",
       "      <td>0.69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>paid_ads</td>\n",
       "      <td>retail</td>\n",
       "      <td>2</td>\n",
       "      <td>83843.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>australia</td>\n",
       "      <td>1</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>referral</td>\n",
       "      <td>education</td>\n",
       "      <td>3</td>\n",
       "      <td>85012.0</td>\n",
       "      <td>self_employed</td>\n",
       "      <td>europe</td>\n",
       "      <td>3</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    lead_source    industry  number_of_courses_viewed  annual_income  \\\n",
       "0      paid_ads         NaN                         1        79450.0   \n",
       "1  social_media      retail                         1        46992.0   \n",
       "2        events  healthcare                         5        78796.0   \n",
       "3      paid_ads      retail                         2        83843.0   \n",
       "4      referral   education                         3        85012.0   \n",
       "\n",
       "  employment_status       location  interaction_count  lead_score  converted  \n",
       "0        unemployed  south_america                  4        0.94          1  \n",
       "1          employed  south_america                  1        0.80          0  \n",
       "2        unemployed      australia                  3        0.69          1  \n",
       "3               NaN      australia                  1        0.87          0  \n",
       "4     self_employed         europe                  3        0.62          1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the lead scoring dataset\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv')\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f59c3d4-1f9a-4a0d-889c-cd1678cd0150",
   "metadata": {},
   "source": [
    "### Dataset Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c214d1f5-1033-45cd-b55e-ba85091d7ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1462 entries, 0 to 1461\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   lead_source               1334 non-null   object \n",
      " 1   industry                  1328 non-null   object \n",
      " 2   number_of_courses_viewed  1462 non-null   int64  \n",
      " 3   annual_income             1281 non-null   float64\n",
      " 4   employment_status         1362 non-null   object \n",
      " 5   location                  1399 non-null   object \n",
      " 6   interaction_count         1462 non-null   int64  \n",
      " 7   lead_score                1462 non-null   float64\n",
      " 8   converted                 1462 non-null   int64  \n",
      "dtypes: float64(2), int64(3), object(4)\n",
      "memory usage: 102.9+ KB\n",
      "\n",
      "Target variable distribution:\n",
      "converted\n",
      "1    905\n",
      "0    557\n",
      "Name: count, dtype: int64\n",
      "Conversion rate: 0.619\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset info:\")\n",
    "df.info()\n",
    "\n",
    "print(\"\\nTarget variable distribution:\")\n",
    "print(df['converted'].value_counts())\n",
    "print(f\"Conversion rate: {df['converted'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67541541-87ee-4fb5-a575-b3bbcb1894ff",
   "metadata": {},
   "source": [
    "### Check for Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7c58d11-49a4-4446-8a26-27839a08d392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      "lead_source: 128 (8.8%)\n",
      "industry: 134 (9.2%)\n",
      "annual_income: 181 (12.4%)\n",
      "employment_status: 100 (6.8%)\n",
      "location: 63 (4.3%)\n",
      "\n",
      "Total missing values: 606\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "missing_counts = df.isnull().sum()\n",
    "print(\"Missing values per column:\")\n",
    "for col, count in missing_counts.items():\n",
    "    if count > 0:\n",
    "        print(f\"{col}: {count} ({count/len(df)*100:.1f}%)\")\n",
    "\n",
    "if missing_counts.sum() == 0:\n",
    "    print(\"\\nNo missing values found in this dataset.\")\n",
    "else:\n",
    "    print(f\"\\nTotal missing values: {missing_counts.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce4807f-4acc-4355-9156-a90112d072f1",
   "metadata": {},
   "source": [
    "###  Identify Feature Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "106feb01-0930-4d4c-b6e5-6bf249eb7485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical features (4): ['lead_source', 'industry', 'employment_status', 'location']\n",
      "Numerical features (4): ['number_of_courses_viewed', 'annual_income', 'interaction_count', 'lead_score']\n"
     ]
    }
   ],
   "source": [
    "# Identify categorical and numerical columns\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Remove target from feature lists\n",
    "if 'converted' in categorical_cols:\n",
    "    categorical_cols.remove('converted')\n",
    "if 'converted' in numerical_cols:\n",
    "    numerical_cols.remove('converted')\n",
    "\n",
    "print(f\"Categorical features ({len(categorical_cols)}): {categorical_cols}\")\n",
    "print(f\"Numerical features ({len(numerical_cols)}): {numerical_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478e0e6a-08b0-4eb9-8ed0-c87afe9a7ec5",
   "metadata": {},
   "source": [
    "### Data Cleaning (Missing Value Treatment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84aaf72c-7dfb-4e42-b541-9b21989800b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values after treatment: 0\n",
      "Data preparation complete!\n"
     ]
    }
   ],
   "source": [
    "# Apply missing value treatment\n",
    "df_clean = df.copy()\n",
    "\n",
    "# For categorical: fill with 'NA'\n",
    "for col in categorical_cols:\n",
    "    df_clean[col] = df_clean[col].fillna('NA')\n",
    "    \n",
    "# For numerical: fill with 0.0  \n",
    "for col in numerical_cols:\n",
    "    df_clean[col] = df_clean[col].fillna(0.0)\n",
    "\n",
    "print(\"Missing values after treatment:\", df_clean.isnull().sum().sum())\n",
    "print(\"Data preparation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6ca7e0-955e-4a94-9098-c1007b767a66",
   "metadata": {},
   "source": [
    "### Most Frequent Industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "773557ed-c838-4bd8-ad3d-b9beddb55832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Industry column value counts:\n",
      "industry\n",
      "retail           203\n",
      "finance          200\n",
      "other            198\n",
      "healthcare       187\n",
      "education        187\n",
      "technology       179\n",
      "manufacturing    174\n",
      "NA               134\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Most frequent observation (mode): retail\n",
      "\n",
      "✓ Q1 Answer: retail\n"
     ]
    }
   ],
   "source": [
    "# Find the mode (most frequent value) for the industry column\n",
    "print(\"Industry column value counts:\")\n",
    "industry_counts = df_clean['industry'].value_counts()\n",
    "print(industry_counts)\n",
    "\n",
    "mode_industry = df_clean['industry'].mode()[0]\n",
    "print(f\"\\nMost frequent observation (mode): {mode_industry}\")\n",
    "\n",
    "print(f\"\\n✓ Q1 Answer: {mode_industry}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08ff924-86f8-447e-a4c5-51d50dc78b1e",
   "metadata": {},
   "source": [
    "### Correlation Matrix Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09e19c30-126e-469c-9aba-f228d2ea6b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation matrix for numerical features:\n",
      "                          number_of_courses_viewed  annual_income  \\\n",
      "number_of_courses_viewed                     1.000          0.010   \n",
      "annual_income                                0.010          1.000   \n",
      "interaction_count                           -0.024          0.027   \n",
      "lead_score                                  -0.005          0.016   \n",
      "\n",
      "                          interaction_count  lead_score  \n",
      "number_of_courses_viewed             -0.024      -0.005  \n",
      "annual_income                         0.027       0.016  \n",
      "interaction_count                     1.000       0.010  \n",
      "lead_score                            0.010       1.000  \n"
     ]
    }
   ],
   "source": [
    "# Create correlation matrix for numerical features only\n",
    "numerical_df = df_clean[numerical_cols]\n",
    "correlation_matrix = numerical_df.corr()\n",
    "\n",
    "print(\"Correlation matrix for numerical features:\")\n",
    "print(correlation_matrix.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363a3a97-6e75-43c4-bb78-86b8a5e6e31d",
   "metadata": {},
   "source": [
    "### Check Specific Correlation Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2210492c-41b0-428f-9774-62e5656cb4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking correlation for specified pairs:\n",
      "interaction_count vs lead_score: 0.0099 (absolute: 0.0099)\n",
      "number_of_courses_viewed vs lead_score: -0.0049 (absolute: 0.0049)\n",
      "number_of_courses_viewed vs interaction_count: -0.0236 (absolute: 0.0236)\n",
      "annual_income vs interaction_count: 0.0270 (absolute: 0.0270)\n",
      "\n",
      "Highest correlation pair: annual_income and interaction_count\n",
      "Absolute correlation: 0.0270\n",
      "\n",
      "✓ Q2 Answer: annual_income and interaction_count\n"
     ]
    }
   ],
   "source": [
    "# Check the specific pairs mentioned in the question\n",
    "pairs_to_check = [\n",
    "    ('interaction_count', 'lead_score'),\n",
    "    ('number_of_courses_viewed', 'lead_score'),\n",
    "    ('number_of_courses_viewed', 'interaction_count'),\n",
    "    ('annual_income', 'interaction_count')\n",
    "]\n",
    "\n",
    "print(\"Checking correlation for specified pairs:\")\n",
    "correlations = {}\n",
    "\n",
    "for col1, col2 in pairs_to_check:\n",
    "    if col1 in correlation_matrix.columns and col2 in correlation_matrix.columns:\n",
    "        corr_value = correlation_matrix.loc[col1, col2]\n",
    "        abs_corr = abs(corr_value)\n",
    "        correlations[(col1, col2)] = abs_corr\n",
    "        print(f\"{col1} vs {col2}: {corr_value:.4f} (absolute: {abs_corr:.4f})\")\n",
    "\n",
    "if correlations:\n",
    "    # Find pair with highest absolute correlation\n",
    "    max_corr_pair = max(correlations.items(), key=lambda x: x[1])\n",
    "    pair_names = max_corr_pair[0]\n",
    "    corr_strength = max_corr_pair[1]\n",
    "    \n",
    "    print(f\"\\nHighest correlation pair: {pair_names[0]} and {pair_names[1]}\")\n",
    "    print(f\"Absolute correlation: {corr_strength:.4f}\")\n",
    "    print(f\"\\n✓ Q2 Answer: {pair_names[0]} and {pair_names[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80b187d-741d-4f19-86bf-04238097f1af",
   "metadata": {},
   "source": [
    "### Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "140c4e65-01b7-4030-ba52-464aed69b8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (1462, 8)\n",
      "Target shape: (1462,)\n",
      "Training set: 876 samples (59.9%)\n",
      "Validation set: 293 samples (20.0%)\n",
      "Test set: 293 samples (20.0%)\n",
      "\n",
      "Class distribution maintained:\n",
      "Train: 0.620, Val: 0.618, Test: 0.618\n"
     ]
    }
   ],
   "source": [
    "# Prepare features and target\n",
    "X = df_clean.drop('converted', axis=1)\n",
    "y = df_clean['converted']\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "\n",
    "# Split: first 80%/20%, then split the 80% into 60%/20% of total\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Now split the remaining 80% into 60% train and 20% val\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp  # 0.25 * 0.8 = 0.2 of total\n",
    ")\n",
    "\n",
    "print(f\"Training set: {len(X_train)} samples ({len(X_train)/len(X):.1%})\")\n",
    "print(f\"Validation set: {len(X_val)} samples ({len(X_val)/len(X):.1%})\")\n",
    "print(f\"Test set: {len(X_test)} samples ({len(X_test)/len(X):.1%})\")\n",
    "\n",
    "print(f\"\\nClass distribution maintained:\")\n",
    "print(f\"Train: {y_train.mean():.3f}, Val: {y_val.mean():.3f}, Test: {y_test.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d06172-330a-4439-92a1-8786bde28ed3",
   "metadata": {},
   "source": [
    "### Mutual Information Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "574f43b2-2124-417b-bd14-2f675ec43ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical features to analyze: ['lead_source', 'industry', 'employment_status', 'location']\n",
      "lead_source: 0.002672 (rounded: 0.0)\n",
      "industry: 0.000707 (rounded: 0.0)\n",
      "employment_status: 0.010330 (rounded: 0.01)\n",
      "location: 0.008639 (rounded: 0.01)\n",
      "\n",
      "Highest mutual information: employment_status (score: 0.01)\n",
      "\n",
      "MI scores for question options:\n",
      "industry: 0.0\n",
      "location: 0.01\n",
      "lead_source: 0.0\n",
      "employment_status: 0.01\n",
      "\n",
      "✓ Q3 Answer: employment_status\n"
     ]
    }
   ],
   "source": [
    "# Calculate mutual information for categorical variables using training data only\n",
    "categorical_features = [col for col in categorical_cols if col in X_train.columns]\n",
    "print(f\"Categorical features to analyze: {categorical_features}\")\n",
    "\n",
    "mutual_info_scores = {}\n",
    "\n",
    "for col in categorical_features:\n",
    "    # Encode categorical feature for mutual_info_classif\n",
    "    le = LabelEncoder()\n",
    "    X_encoded = le.fit_transform(X_train[col].astype(str))\n",
    "    \n",
    "    # Calculate mutual information\n",
    "    mi_score = mutual_info_classif(\n",
    "        X_encoded.reshape(-1, 1), \n",
    "        y_train, \n",
    "        random_state=42\n",
    "    )[0]\n",
    "    \n",
    "    mutual_info_scores[col] = round(mi_score, 2)\n",
    "    print(f\"{col}: {mi_score:.6f} (rounded: {round(mi_score, 2)})\")\n",
    "\n",
    "# Find variable with highest MI score\n",
    "max_mi_var = max(mutual_info_scores.items(), key=lambda x: x[1])\n",
    "print(f\"\\nHighest mutual information: {max_mi_var[0]} (score: {max_mi_var[1]})\")\n",
    "\n",
    "# Check against options: industry, location, lead_source, employment_status\n",
    "options = ['industry', 'location', 'lead_source', 'employment_status']\n",
    "print(f\"\\nMI scores for question options:\")\n",
    "for opt in options:\n",
    "    if opt in mutual_info_scores:\n",
    "        print(f\"{opt}: {mutual_info_scores[opt]}\")\n",
    "\n",
    "print(f\"\\n✓ Q3 Answer: {max_mi_var[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5436cd62-46b8-4e74-bbf4-e02fb980e2c9",
   "metadata": {},
   "source": [
    "### Prepare Data for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dff8e785-9c60-43b4-b398-59d27814c3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical features: 4\n",
      "Categorical features: 4\n",
      "Encoded categorical features: 27 features\n",
      "Final training features shape: (876, 31)\n",
      "Final validation features shape: (293, 31)\n"
     ]
    }
   ],
   "source": [
    "# Separate numerical and categorical features for encoding\n",
    "X_train_num = X_train[numerical_cols]\n",
    "X_train_cat = X_train[categorical_features]\n",
    "\n",
    "X_val_num = X_val[numerical_cols]\n",
    "X_val_cat = X_val[categorical_features]\n",
    "\n",
    "print(f\"Numerical features: {X_train_num.shape[1]}\")\n",
    "print(f\"Categorical features: {X_train_cat.shape[1]}\")\n",
    "\n",
    "# Apply one-hot encoding to categorical features\n",
    "ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "\n",
    "# Fit on training data and transform both sets\n",
    "X_train_cat_encoded = ohe.fit_transform(X_train_cat)\n",
    "X_val_cat_encoded = ohe.transform(X_val_cat)\n",
    "\n",
    "print(f\"Encoded categorical features: {X_train_cat_encoded.shape[1]} features\")\n",
    "\n",
    "# Combine numerical and encoded categorical features\n",
    "X_train_final = np.hstack([X_train_num.values, X_train_cat_encoded])\n",
    "X_val_final = np.hstack([X_val_num.values, X_val_cat_encoded])\n",
    "\n",
    "print(f\"Final training features shape: {X_train_final.shape}\")\n",
    "print(f\"Final validation features shape: {X_val_final.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe82bb7-1f56-49a0-8a2a-f82e7cd50b37",
   "metadata": {},
   "source": [
    "### Train Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f3ef8a2-d2e3-4e7d-bb91-83e8b6de8ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained successfully!\n",
      "\n",
      "Validation accuracy: 0.730375\n",
      "Rounded to 2 decimals: 0.73\n",
      "\n",
      "✓ Q4 Answer: 0.73\n"
     ]
    }
   ],
   "source": [
    "# Train logistic regression with specified parameters\n",
    "model = LogisticRegression(\n",
    "    solver='liblinear', \n",
    "    C=1.0, \n",
    "    max_iter=1000, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model.fit(X_train_final, y_train)\n",
    "print(\"Model trained successfully!\")\n",
    "\n",
    "# Calculate accuracy on validation set\n",
    "y_val_pred = model.predict(X_val_final)\n",
    "accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "print(f\"\\nValidation accuracy: {accuracy:.6f}\")\n",
    "print(f\"Rounded to 2 decimals: {round(accuracy, 2)}\")\n",
    "\n",
    "print(f\"\\n✓ Q4 Answer: {round(accuracy, 2)}\")\n",
    "\n",
    "# Store for later use\n",
    "original_accuracy = accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad80df08-34bd-400f-a6d4-9dc6f743fdb4",
   "metadata": {},
   "source": [
    "### Feature Elimination Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da0c1d8f-b685-4a3e-a6ab-ef6c8ee7d0ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original accuracy (for reference): 0.730375\n",
      "\n",
      "Testing feature elimination:\n",
      "\n",
      "--- Testing removal of 'industry' ---\n",
      "Removed categorical feature 'industry'\n",
      "Reduced features shape: (876, 23)\n",
      "Accuracy without 'industry': 0.730375\n",
      "Difference: 0.000000\n",
      "\n",
      "--- Testing removal of 'employment_status' ---\n",
      "Removed categorical feature 'employment_status'\n",
      "Reduced features shape: (876, 26)\n",
      "Accuracy without 'employment_status': 0.733788\n",
      "Difference: -0.003413\n",
      "\n",
      "--- Testing removal of 'lead_score' ---\n",
      "Removed numerical feature 'lead_score'\n",
      "Reduced features shape: (876, 30)\n",
      "Accuracy without 'lead_score': 0.730375\n",
      "Difference: 0.000000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Original accuracy (for reference): {original_accuracy:.6f}\")\n",
    "\n",
    "# Features to test for elimination\n",
    "features_to_test = ['industry', 'employment_status', 'lead_score']\n",
    "feature_differences = {}\n",
    "\n",
    "print(\"\\nTesting feature elimination:\")\n",
    "\n",
    "for feature_name in features_to_test:\n",
    "    print(f\"\\n--- Testing removal of '{feature_name}' ---\")\n",
    "    \n",
    "    if feature_name in numerical_cols:\n",
    "        # Remove numerical feature\n",
    "        remaining_num_cols = [col for col in numerical_cols if col != feature_name]\n",
    "        X_train_reduced_num = X_train[remaining_num_cols]\n",
    "        X_val_reduced_num = X_val[remaining_num_cols]\n",
    "        \n",
    "        # Keep all categorical features (re-encode)\n",
    "        X_train_reduced = np.hstack([X_train_reduced_num.values, X_train_cat_encoded])\n",
    "        X_val_reduced = np.hstack([X_val_reduced_num.values, X_val_cat_encoded])\n",
    "        \n",
    "        print(f\"Removed numerical feature '{feature_name}'\")\n",
    "        \n",
    "    elif feature_name in categorical_features:\n",
    "        # Remove categorical feature\n",
    "        remaining_cat_cols = [col for col in categorical_features if col != feature_name]\n",
    "        X_train_cat_reduced = X_train[remaining_cat_cols]\n",
    "        X_val_cat_reduced = X_val[remaining_cat_cols]\n",
    "        \n",
    "        # Re-encode without the removed feature\n",
    "        ohe_reduced = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "        X_train_cat_reduced_encoded = ohe_reduced.fit_transform(X_train_cat_reduced)\n",
    "        X_val_cat_reduced_encoded = ohe_reduced.transform(X_val_cat_reduced)\n",
    "        \n",
    "        # Keep all numerical features\n",
    "        X_train_reduced = np.hstack([X_train_num.values, X_train_cat_reduced_encoded])\n",
    "        X_val_reduced = np.hstack([X_val_num.values, X_val_cat_reduced_encoded])\n",
    "        \n",
    "        print(f\"Removed categorical feature '{feature_name}'\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"Feature '{feature_name}' not found in either numerical or categorical features\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"Reduced features shape: {X_train_reduced.shape}\")\n",
    "    \n",
    "    # Train model without this feature\n",
    "    model_reduced = LogisticRegression(\n",
    "        solver='liblinear', \n",
    "        C=1.0, \n",
    "        max_iter=1000, \n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    model_reduced.fit(X_train_reduced, y_train)\n",
    "    y_val_pred_reduced = model_reduced.predict(X_val_reduced)\n",
    "    accuracy_reduced = accuracy_score(y_val, y_val_pred_reduced)\n",
    "    \n",
    "    # Calculate difference (original - reduced)\n",
    "    difference = original_accuracy - accuracy_reduced\n",
    "    feature_differences[feature_name] = difference\n",
    "    \n",
    "    print(f\"Accuracy without '{feature_name}': {accuracy_reduced:.6f}\")\n",
    "    print(f\"Difference: {difference:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a16421-bc1e-439f-9fb6-1214a5654346",
   "metadata": {},
   "source": [
    "### Find Feature with Smallest Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20464e16-dc56-4f41-991c-d22599cd99d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Feature Elimination Summary ===\n",
      "industry: difference = 0.000000\n",
      "employment_status: difference = -0.003413\n",
      "lead_score: difference = 0.000000\n",
      "\n",
      "Feature with smallest difference: industry\n",
      "Difference: 0.000000\n",
      "\n",
      "✓ Q5 Answer: industry\n"
     ]
    }
   ],
   "source": [
    "# Summary and find feature with smallest difference\n",
    "print(\"\\n=== Feature Elimination Summary ===\")\n",
    "for feature, diff in feature_differences.items():\n",
    "    print(f\"{feature}: difference = {diff:.6f}\")\n",
    "\n",
    "# Find feature with smallest absolute difference\n",
    "min_diff_feature = min(feature_differences.items(), key=lambda x: abs(x[1]))\n",
    "\n",
    "print(f\"\\nFeature with smallest difference: {min_diff_feature[0]}\")\n",
    "print(f\"Difference: {min_diff_feature[1]:.6f}\")\n",
    "\n",
    "print(f\"\\n✓ Q5 Answer: {min_diff_feature[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b419745e-28a1-41d9-869b-38a952f47a7b",
   "metadata": {},
   "source": [
    "### Regularized Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd0f01a0-d806-47a2-b557-b68dc1665754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing different C values for regularization:\n",
      "(Lower C = more regularization)\n",
      "C=0.01: accuracy = 0.733788 (rounded to 3 decimals: 0.734)\n",
      "C=0.1: accuracy = 0.730375 (rounded to 3 decimals: 0.73)\n",
      "C=1: accuracy = 0.730375 (rounded to 3 decimals: 0.73)\n",
      "C=10: accuracy = 0.730375 (rounded to 3 decimals: 0.73)\n",
      "C=100: accuracy = 0.730375 (rounded to 3 decimals: 0.73)\n"
     ]
    }
   ],
   "source": [
    "# Test different regularization parameters\n",
    "C_values = [0.01, 0.1, 1, 10, 100]\n",
    "C_accuracies = {}\n",
    "\n",
    "print(\"Testing different C values for regularization:\")\n",
    "print(\"(Lower C = more regularization)\")\n",
    "\n",
    "for C in C_values:\n",
    "    # Train model with different C value\n",
    "    model_reg = LogisticRegression(\n",
    "        solver='liblinear', \n",
    "        C=C, \n",
    "        max_iter=1000, \n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    model_reg.fit(X_train_final, y_train)\n",
    "    y_val_pred_reg = model_reg.predict(X_val_final)\n",
    "    accuracy_reg = accuracy_score(y_val, y_val_pred_reg)\n",
    "    \n",
    "    C_accuracies[C] = accuracy_reg\n",
    "    print(f\"C={C}: accuracy = {accuracy_reg:.6f} (rounded to 3 decimals: {round(accuracy_reg, 3)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c599be5d-a8df-4ca1-8888-2eca89953b4b",
   "metadata": {},
   "source": [
    "### Find Best C Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b87371e-dff9-4d49-8486-ad7904159f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Regularization Results ===\n",
      "C=0.01: 0.734\n",
      "C=0.1: 0.73\n",
      "C=1: 0.73\n",
      "C=10: 0.73\n",
      "C=100: 0.73\n",
      "\n",
      "Best accuracy: 0.734\n",
      "Best C value: 0.01\n",
      "\n",
      "✓ Q6 Answer: 0.01\n"
     ]
    }
   ],
   "source": [
    "# Find best C value\n",
    "print(\"\\n=== Regularization Results ===\")\n",
    "for C, acc in C_accuracies.items():\n",
    "    print(f\"C={C}: {round(acc, 3)}\")\n",
    "\n",
    "# Find C with highest accuracy (if tie, select smallest C)\n",
    "max_accuracy = max(C_accuracies.values())\n",
    "best_C_candidates = [C for C, acc in C_accuracies.items() if acc == max_accuracy]\n",
    "best_C = min(best_C_candidates)  # Select smallest C in case of tie\n",
    "\n",
    "print(f\"\\nBest accuracy: {round(max_accuracy, 3)}\")\n",
    "print(f\"Best C value: {best_C}\")\n",
    "\n",
    "if len(best_C_candidates) > 1:\n",
    "    print(f\"Note: Multiple C values had the same accuracy, selected smallest: {best_C}\")\n",
    "\n",
    "print(f\"\\n✓ Q6 Answer: {best_C}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9501b656-a26f-4b5c-a072-cdad2202da73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
